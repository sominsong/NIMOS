import requests
from requests.adapters import HTTPAdapter
import hyperlink
from matplotlib.font_manager import json_dump
from bs4 import BeautifulSoup as bs
import json
import re
import time

exploit_cve_data = []
kernel_link = 'git.kernel.org'

def get_data_from_link(link):

    file_func = []
    file_set = set()
    response = requests.get(link, verify=False)
    if response.status_code == 200:
        html = response.text
        soup = bs(response.text, 'html')

        file = soup.select_one('#cgit > div.content > table.diff > tbody > tr > td > div.head > a')
        file_head = file.get_text()

        file_list = soup.find_all('div', {'class':'hunk'})
        for file in file_list:
            file = file.get_text()
            last_idx = -1
            for idx in range(len(file)):
                if file[idx] == '@':
                    last_idx = idx
            file = file[last_idx + 1:]
            if file in file_set:
                continue
            else:
                file_set.add(file)

        for file in file_set:
            file_func.append(file)

    return file_head, file_func
            

def get_data_from_desc(desc):
    text = desc.split()
    diff_func = "None"
    diff_file = "None"
    for i in range(len(text)):
        if text[i] == 'function':
            diff_func = text[i - 1]
        elif text[i] == 'file':
            diff_file = text[i - 1]
        elif '.c' in text[i] or '.h' in text[i] or '.S' in text[i]:
            diff_file = text[i]
    return diff_file, diff_func

def write_json(cve_id, current_description, diff_desc_file, diff_desc_func, patch_url, patch_diff_file, patch_diff_func):
    cve_dict = dict()
    
    cve_dict["CVE-ID"] = cve_id
    cve_dict["current_description"] = current_description
    cve_dict["file"] = diff_desc_file
    cve_dict["function"] = diff_desc_func
    #write patch data per patch url 
    if len(patch_url) == 0:
        cve_dict["patch_url"] = "None"
    else:
        idx = 0 
        patch_index = 1
        patch_dict = dict()
        for url in patch_url:
            patch_dict_url = dict()
            patch_dict_url["patch_url"] = url
            if kernel_link in url:
                patch_dict_url["patch_file"] = patch_diff_file[idx]
                patch_dict_url["patch_function"] = patch_diff_func[idx]
                idx = idx + 1 
            patch_dict[f"patch_{patch_index}"] = patch_dict_url   
            patch_index = patch_index + 1
        cve_dict["patch"] = patch_dict

    with open('cve_crawling_result_final_3.json', 'a', encoding='utf-8') as f:
        json.dump(cve_dict, f, indent= '\t')


def get_response(url, cve_id):

    response = requests.get(url, verify = False)

    if response.status_code == 200:
        html = response.text
        soup = bs(response.text, 'html')

        text = soup.select_one('#vulnDetailTableView > tbody > tr > td > div > div.col-lg-9.col-md-7.col-sm-12 > p')
        current_description = text.get_text()

        hyperlink_table = soup.select_one('#vulnHyperlinksPanel > table > tbody').find_all()
        patch_url = []
        patch_diff_file = []
        patch_diff_func = []
        diff_desc_file = "None"
        diff_desc_func = "None"
        

        for x in range(0, len(hyperlink_table)):
            data = hyperlink_table[x].find_all('td')
            for y in range(0, len(data)):
                hyperlink_link = data[0].get_text()
                element = data[y].find_all('span')
                for z in range(0, len(element)):
                    patch = element[z].get_text()
                    if(patch == 'Patch'):
                        patch_url.append(hyperlink_link)
                        if kernel_link in hyperlink_link:
                            diff_file, diff_func = get_data_from_link(hyperlink_link)
                            patch_diff_file.append(diff_file)
                            patch_diff_func.append(diff_func)
                        else:
                            diff_desc_file, diff_desc_func = get_data_from_desc(current_description)
            
        write_json(cve_id, current_description, diff_desc_file, diff_desc_func, patch_url, patch_diff_file, patch_diff_func)
    else:
        print(url)
        print("url 연결 문제")




if __name__ == '__main__':
    
    with open('exploit.json', 'r') as f:
        exploit_data = json.load(f)
    for line in exploit_data:
        line = line['CVE-ID']
        for x in range(len(line)):
            target_cve_id = line[x]
            if str(target_cve_id) == "None":
                continue
            target_url = "https://nvd.nist.gov/vuln/detail/CVE-" + str(target_cve_id)
            get_response(target_url, target_cve_id)  